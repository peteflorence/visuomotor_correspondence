{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import spartan.utils.utils as spartan_utils\n",
    "from imitation_agent.dataset.function_factory import ObservationFunctionFactory, ActionFunctionFactory\n",
    "from imitation_agent.dataset.imitation_episode_sequence_dataset import ImitationEpisodeSequenceDataset\n",
    "from imitation_agent.dataset.imitation_episode_dataset import ImitationEpisodeDataset\n",
    "spartan_source_dir = spartan_utils.getSpartanSourceDir()\n",
    "logs_config_yaml = os.path.join(spartan_source_dir, \"modules/imitation_agent/config/task/move_to_box_0710.yaml\")\n",
    "logs_config = spartan_utils.getDictFromYamlFilename(logs_config_yaml)\n",
    "\n",
    "imitation_src_dir = os.path.join(spartan_source_dir, \"modules/imitation_agent\")\n",
    "data_dir = spartan_utils.get_data_dir()\n",
    "logs_dir_path = os.path.join(data_dir, \"pdc/imitation/move_to_box_0710\")\n",
    "\n",
    "config_yaml = os.path.join(imitation_src_dir, \"config\", \"model\", \"mlp_stateless_position.yaml\")\n",
    "config = spartan_utils.getDictFromYamlFilename(config_yaml)\n",
    "\n",
    "obs_function = ObservationFunctionFactory.get_function(config)\n",
    "action_function = ActionFunctionFactory.action_from_config(config)\n",
    "dataset = ImitationEpisodeDataset(logs_dir_path, logs_config, config,\n",
    "                                  action_function=action_function,\n",
    "                                  observation_function=obs_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib  import cm\n",
    "\n",
    "def get_min_max_rewards(df):\n",
    "    first = True\n",
    "    for index, row in df.iterrows():\n",
    "        if first:\n",
    "            min_r = row[\"reward\"]\n",
    "            max_r = row[\"reward\"]\n",
    "            first = False\n",
    "            continue\n",
    "        if row[\"reward\"] > max_r:\n",
    "            max_r = row[\"reward\"]\n",
    "        if row[\"reward\"] < min_r:\n",
    "            min_r = row[\"reward\"]\n",
    "    return min_r, max_r\n",
    "        \n",
    "def get_normed_reward(reward, min_r, max_r):\n",
    "    return (reward - min_r)/(max_r-min_r)\n",
    "        \n",
    "        \n",
    "def create_distribution_plots(ax, df, dataset, min_r, max_r, first):\n",
    "    \n",
    "    xs = []\n",
    "    ys = []\n",
    "    cs = []\n",
    "    \n",
    "    # plot heatmap\n",
    "    for index, row in df.iterrows():\n",
    "        object_position = row[\"object_position\"].strip(\"[\").strip(\"]\").split(\",\")\n",
    "        object_position = [float(x) for x in object_position]\n",
    "        object_position = np.asarray(object_position)\n",
    "        reward = row[\"reward\"]\n",
    "        #jet = cm.get_cmap(\"jet\")\n",
    "        #jet = cm.get_cmap(\"coolwarm\")\n",
    "        #normed_reward = (-1.0*get_normed_reward(reward, min_r, max_r))+1.0\n",
    "        #normed_reward = get_normed_reward(reward, min_r, max_r)\n",
    "        xs.append(object_position[0])\n",
    "        ys.append(object_position[1])\n",
    "        #cs.append(jet(normed_reward))\n",
    "        cs.append(reward)\n",
    "    [xs, ys, cs] = [np.asarray(x) for x in [xs,ys,cs]]\n",
    "    \n",
    "    hm = ax.scatter(xs, ys, c=cs, vmin=min_r, vmax=max_r, cmap = cm.coolwarm_r)\n",
    "    #hm = ax.scatter(ys, xs, c=cs, cmap = cm.coolwarm_r)\n",
    "    #plt.colorbar(hm)\n",
    "            \n",
    "    # plot training examples\n",
    "    for log_name in dataset.episodes.keys():\n",
    "        episode = dataset.episodes[log_name]\n",
    "        object_pose_trained = episode.sim_config_dict[\"instances\"][0][\"q0\"]\n",
    "        sc = ax.scatter(object_pose_trained[0], object_pose_trained[1], c=\"gray\", alpha=0.4, marker=\"x\")\n",
    "    \n",
    "    ax.axis('equal')\n",
    "    ax.set(ylim=(-0.2, 0.2), xlim=(0.6, 0.7))\n",
    "    ax.set_title(row['name'])\n",
    "    if not first:\n",
    "        #ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    else:\n",
    "        ax.set_ylabel(\"y, box position\")\n",
    "        ax.set_xlabel(\"x, box position\")\n",
    "    return hm\n",
    "    \n",
    "        \n",
    "dfs = []  \n",
    "\n",
    "folders = []\n",
    "for folder in sorted(os.listdir(os.path.join(spartan_source_dir, \"sandbox/experiment_01-aug5\"))):\n",
    "    print folder\n",
    "    folders.append(folder)\n",
    "    path_to_move_to_box_folder = os.path.join(spartan_source_dir, \"sandbox\",\"experiment_01-aug5\",folder)\n",
    "    path_to_csv = os.path.join(path_to_move_to_box_folder, \"results.csv\")\n",
    "    df = pd.read_csv(path_to_csv, index_col=0)\n",
    "    df[\"name\"] = folder[3:]\n",
    "    dfs.append(df)\n",
    "    \n",
    "min = 1e6\n",
    "max = -1e6\n",
    "for df in dfs:\n",
    "    this_min, this_max = get_min_max_rewards(df)\n",
    "    if this_min < min:\n",
    "        min = this_min\n",
    "    if this_max > max:\n",
    "        max = this_max\n",
    "        \n",
    "# SETTING THIS MANUALLY FOR SCALE\n",
    "min = -10\n",
    "\n",
    "fig, axes = plt.subplots(ncols=len(dfs),nrows=1)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(15)\n",
    "for i, df in enumerate(dfs):\n",
    "    ax = axes[i]\n",
    "    if i == 0:\n",
    "        first = True\n",
    "    else:\n",
    "        first = False\n",
    "    hm = create_distribution_plots(ax, df, dataset, min, max, first=first)\n",
    "#plt.colorbar(hm, pad=0.2)\n",
    "\n",
    "cbaxes = fig.add_axes([0.92, 0.12, 0.02, 0.76]) \n",
    "cb = plt.colorbar(hm, cax = cbaxes) \n",
    "cb.set_label('Task success metric (higher is better)', labelpad=20, rotation=270)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tensorflow_log(axes, path, color, label):\n",
    "\n",
    "    event_acc = EventAccumulator(path)#, tf_size_guidance)\n",
    "    event_acc.Reload()\n",
    "\n",
    "    # Show all tags in the log file\n",
    "    #print(event_acc.Tags())\n",
    "\n",
    "    training_accuracies =   event_acc.Scalars('loss')\n",
    "    validation_accuracies = event_acc.Scalars('test_loss_average')\n",
    "\n",
    "    x_train_steps = []\n",
    "    x_train_values = []\n",
    "    \n",
    "    \n",
    "    for i in xrange(len(training_accuracies)):\n",
    "        x_train_steps.append(training_accuracies[i][1]) # 1 is step\n",
    "        x_train_values.append(training_accuracies[i][2]) # 2 is step\n",
    "    \n",
    "#     from scipy.signal import savgol_filter\n",
    "#     x_train_values_filt = savgol_filter(x_train_values, 21, 2)\n",
    "\n",
    "    #from scipy.signal import medfilt\n",
    "    #x_train_values_filt = medfilt(x_train_values, 21)\n",
    "    \n",
    "    w = 0.90\n",
    "    x_train_values = np.asarray(x_train_values)\n",
    "    x_train_values_filt = x_train_values*0.0\n",
    "    x_train_values_filt[0] = x_train_values[0]\n",
    "    for i, v in enumerate(x_train_values[1:]):\n",
    "        x_train_values_filt[i+1] = x_train_values_filt[i]*w + (1-w)*x_train_values[i]\n",
    "   \n",
    "    \n",
    "#     from scipy import signal\n",
    "#     xn = x_train_values\n",
    "#     b, a = signal.butter(3, 0.05)\n",
    "#     zi = signal.lfilter_zi(b, a)\n",
    "#     z, _ = signal.lfilter(b, a, xn, zi=zi*xn[0])\n",
    "#     z2, _ = signal.lfilter(b, a, z, zi=zi*z[0])\n",
    "#     y = signal.filtfilt(b, a, xn)\n",
    "#     x_train_values_filt = y\n",
    "\n",
    "        \n",
    "    x_validation_steps = []\n",
    "    x_validation_values = []\n",
    "    \n",
    "    for i in xrange(len(validation_accuracies)):\n",
    "        x_validation_steps.append(validation_accuracies[i][1])\n",
    "        x_validation_values.append(validation_accuracies[i][2])\n",
    "        \n",
    "\n",
    "    axes[0].plot(np.asarray(x_train_steps), np.asarray(x_train_values_filt), color=color, label=label, alpha=1.0)\n",
    "    axes[0].plot(np.asarray(x_train_steps), np.asarray(x_train_values), color=color, alpha=0.1)\n",
    "    axes[1].plot(np.asarray(x_validation_steps), np.asarray(x_validation_values), label=label, color=color)\n",
    "\n",
    "    axes[0].set_xlabel(\"Steps\")\n",
    "    axes[1].set_xlabel(\"Steps\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[1].set_ylabel(\"Loss\")\n",
    "    axes[0].set_title(\"Train\")\n",
    "    axes[0].set(ylim=(0.6e-4, 1.5e-4))\n",
    "    axes[1].set(ylim=(0.6e-4, 1.5e-4))\n",
    "    axes[1].set_title(\"Validation\")\n",
    "\n",
    "\n",
    "def get_tf_events_file(path):\n",
    "    return sorted(os.listdir(path))[-1]\n",
    "    \n",
    "base = os.path.join(data_dir, \"pdc/imitation/trained_models/mlp_position/experiment_01-aug5\")\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2,nrows=1)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "\n",
    "\n",
    "#colors = [\"black\", \"red\", \"orange\", \"green\", \"blue\", \"purple\"]\n",
    "colors = [\"red\", \"orange\", \"green\", \"blue\", \"purple\"]\n",
    "\n",
    "#folders.insert(0,\"00-blind\")\n",
    "#folders.remove(\"00-blind\")\n",
    "\n",
    "counter = 0\n",
    "for color, folder in zip(colors, folders):\n",
    "    counter+=1\n",
    "    path_to = os.path.join(base,folder,\"tensorboard\")\n",
    "    tf_file = get_tf_events_file(path_to)\n",
    "    tf_file_full = os.path.join(path_to, tf_file)\n",
    "    plot_tensorflow_log(axes, tf_file_full, color, label=folder[3:])\n",
    "#     if counter == 2:\n",
    "#         break\n",
    "    \n",
    "axes[0].ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "axes[1].ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.legend(loc='upper right', frameon=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Training times\"\n",
    "print \"---------------\"\n",
    "import datetime\n",
    "\n",
    "for folder in folders:\n",
    "    path_to = os.path.join(base,folder,\"tensorboard\")\n",
    "    tf_file = get_tf_events_file(path_to)\n",
    "    tf_file_full = os.path.join(path_to, tf_file)\n",
    "    event_acc = EventAccumulator(tf_file_full)#, tf_size_guidance)\n",
    "    event_acc.Reload()\n",
    "    training_accuracies =   event_acc.Scalars('loss')\n",
    "    seconds = training_accuracies[-1][0] - training_accuracies[0][0]\n",
    "    #print str(datetime.timedelta(seconds=seconds)) \n",
    "    #print '%d hr, %d minutes, %02d seconds' % (seconds / 60 / 60,  seconds/ 60 % 60, seconds % 60)\n",
    "    print '{:25}'.format(folder[3:]),  '%d hr, %d minutes' % (seconds / 60 / 60,  seconds/ 60 % 60)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_drift_plot(dfs):\n",
    "    for df in dfs:\n",
    "        plt.scatter(df[\"index\"], df[\"termination_time\"])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.scatter(dfs[-1][\"index\"], df[\"termination_time\"])\n",
    "    plt.show()\n",
    "    \n",
    "create_time_drift_plot(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "def create_violin_plot(dfs):\n",
    "    df_all = pd.concat(dfs)\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    ax = sns.violinplot(x=df_all[\"name\"], y=df_all[\"reward\"])\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(15, 4)\n",
    "    plt.show()\n",
    "    \n",
    "create_violin_plot(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# great example: https://seaborn.pydata.org/examples/distplot_options.html\n",
    "# full documentation: https://seaborn.pydata.org/generated/seaborn.distplot.html\n",
    "def create_dist_plot(dfs):\n",
    "    df_all = pd.concat(dfs)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(dfs), figsize=(9, 3), sharey=True)\n",
    "    #axes[0].set_ylim([-20,0])\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    for i, df in enumerate(dfs):\n",
    "        sns.distplot(df[\"reward\"], vertical=True, ax=axes[i], bins=20)\n",
    "        #ax = sns.violinplot(x=df_all[\"name\"], y=df_all[\"reward\"])\n",
    "        #fig = matplotlib.pyplot.gcf()\n",
    "        #fig.set_size_inches(18.5, 10.5)\n",
    "    plt.show()\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(dfs), figsize=(9, 3), sharey=True)\n",
    "    axes[0].set_ylim([-2,-1])\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    for i, df in enumerate(dfs):\n",
    "        sns.distplot(df[\"reward\"], vertical=True, ax=axes[i], bins=20, rug=True)\n",
    "        #ax = sns.violinplot(x=df_all[\"name\"], y=df_all[\"reward\"])\n",
    "        #fig = matplotlib.pyplot.gcf()\n",
    "        #fig.set_size_inches(18.5, 10.5)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "create_dist_plot(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
