num_downsampled_logs: 200

#use_vision: False         # SET IN SCRIPT
camera_num: 0
deploy_image_topic: "/camera_sim_d415_left/rgb/image_rect_color"
use_depth: False
use_hard_3D_unprojection: False
use_soft_3D_unprojection: False
#precompute_features: True # SET IN SCRIPT
precompute_only_first_frame_features: False
#freeze_vision: True       # SET IN SCRIPT
precompute_descriptor_images: False
surf_descriptors: False

regression_type: "direct"
num_gaussians:   2

# training params
#global_training_steps: 50000 # SET IN SCRIPT
batch_size: 16                 # needs to be 1 if sequence
lr: 1.0e-4
weight_decay: 0.0e-4
momentum: 0.9
alpha:    0.9                 # for RMSprop
save_rate_iteration: 10000
learning_rate_decay: 0.5
steps_between_learning_rate_decay: 10000
num_workers: 12
sigma_noise_augmentation: 0.006
divide_by_std: True
action_bias: 0
test_loss_rate_iterations: 2000
position_noise_augmentation_sigma: 0.001 # meters
rotation_noise_augmentation_sigma: 1.0 # degrees, will be angle-axis

# filters out indices with little movement
filtering:
  filter_no_movement: False
  translation_threshold: 0.001
  rotation_threshold_degrees: 1.0 # degrees
  gripper_width_threshold: 0.01

observation:
  type: "ee_position_history_observation"
  config:
      history: [0]
      ee_points:
        - [0.0, 0, 0]
#        - [0, 0.1, 0]
#        - [0, 0, 0.1]
      angle_axis_relative_to_nominal:
        x: False
        y: False
        z: False
      gripper:
        width: False

# output
action:
  type: ""
  config:
    translation:
      x: False
      y: False
      z: False
    rpy:
      roll:  False
      pitch: False
      yaw:   False
    quaternion: False
    translation_delta:
      x: False
      y: False
      z: False
    translation_delta_world_frame:
      x: True
      y: True
      z: True
    angle_axis_delta: # in gripper frame
      x: False
      y: False
      z: False
    angle_axis_relative_to_nominal:
      x: False
      y: False
      z: False
    gripper:
      width: False


loss_scaling: [1.0, 1.0, 1.0]

model:
  # vision_net: DonSpatialSoftmax # none, DonSpatialSoftmax, SpatialAutoencoder, EndToEnd # SET IN SCRIPT
  descriptor_net: "/home/peteflo/data/pdc/trained_models/imitation/sugar_spatial_0710_3/010000.pth"
  #descriptor_net: "/home/peteflo/data/pdc/trained_models/imitation/sugar_flip_spatial_0716_augmented_3/010000.pth"
  #descriptor_net: "/home/peteflo/data/pdc/trained_models/imitation/sugar_flip_spatial_0716_3/010000.pth"

  #autoencoder_net: "/home/peteflo/spartan/modules/imitation_agent/model/2019-09-03-21-39-49/dsae_3.pth"
  #autoencoder_net: "/home/peteflo/spartan/modules/imitation_agent/model/2019-09-04-17-50-32/dsae_7.pth"
  autoencoder_net: "/home/peteflo/spartan/modules/imitation_agent/model/2019-09-04-21-29-12/dsae_7.pth"

  #descriptor_net: "/home/peteflo/data/pdc/trained_models/imitation/sugar_spatial_longer_3/010002.pth"
  # only used for those that crop images
  u_range_start: 0   # clear for camera left
  u_range_end: 640   # clear for camera left
  policy_net: "mlp_stateless"
  config:
    units_per_layer: [128, 128]
    dropout_prob: 0.2
    #num_ref_descriptors: 1      # SET IN SCRIPT
    use_xyz_passthrough_every_layer: False


# ONLY FOR ANALYSIS
#use_gt_object_pose: False       # SET IN SCRIPT
#project_pose_into_camera: False # SET IN SCRIPT