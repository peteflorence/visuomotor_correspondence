{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "import spartan.utils.utils as spartan_utils\n",
    "from imitation_agent.dataset.function_factory import ObservationFunctionFactory, ActionFunctionFactory\n",
    "from imitation_agent.dataset.imitation_episode_sequence_dataset import ImitationEpisodeSequenceDataset\n",
    "from imitation_agent.dataset.imitation_episode_dataset import ImitationEpisodeDataset\n",
    "from imitation_agent.training import train_utils\n",
    "\n",
    "spartan_source_dir = spartan_utils.getSpartanSourceDir()\n",
    "logs_config_yaml = os.path.join(spartan_source_dir, \"modules/imitation_agent/config/task/move_to_box_se2_box_in_frame.yaml\")\n",
    "logs_config = spartan_utils.getDictFromYamlFilename(logs_config_yaml)\n",
    "\n",
    "imitation_src_dir = os.path.join(spartan_source_dir, \"modules/imitation_agent\")\n",
    "data_dir = spartan_utils.get_data_dir()\n",
    "logs_dir_path = os.path.join(data_dir, \"pdc/imitation/move_to_box_se2\")\n",
    "\n",
    "config_yaml = os.path.join(imitation_src_dir, \"config\", \"model\", \"mlp_stateless_position.yaml\")\n",
    "config = spartan_utils.getDictFromYamlFilename(config_yaml)\n",
    "\n",
    "\n",
    "def get_dataset(num_logs):\n",
    "    NUM_LOGS = num_logs\n",
    "    logs_config_downsampled = train_utils.deterministic_downsample(logs_config, NUM_LOGS)\n",
    "    NUM_LOGS=str(NUM_LOGS)\n",
    "\n",
    "    obs_function = ObservationFunctionFactory.get_function(config)\n",
    "    action_function = ActionFunctionFactory.action_from_config(config)\n",
    "    dataset = ImitationEpisodeDataset(logs_dir_path, logs_config_downsampled, config,\n",
    "                                      action_function=action_function,\n",
    "                                      observation_function=obs_function)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_logs in [200,100,50,30]:\n",
    "    \n",
    "    dataset = get_dataset(num_logs)\n",
    "    NUM_LOGS = str(num_logs)\n",
    "    \n",
    "    from matplotlib  import cm\n",
    "    import matplotlib\n",
    "\n",
    "    def get_min_max_rewards(df):\n",
    "        first = True\n",
    "        for index, row in df.iterrows():\n",
    "            if first:\n",
    "                min_r = row[\"reward\"]\n",
    "                max_r = row[\"reward\"]\n",
    "                first = False\n",
    "                continue\n",
    "            if row[\"reward\"] > max_r:\n",
    "                max_r = row[\"reward\"]\n",
    "            if row[\"reward\"] < min_r:\n",
    "                min_r = row[\"reward\"]\n",
    "        return min_r, max_r\n",
    "\n",
    "    def get_normed_reward(reward, min_r, max_r):\n",
    "        return (reward - min_r)/(max_r-min_r)\n",
    "\n",
    "    from spartan.utils import transformations\n",
    "    from imitation_agent.utils.visibility_utils import check_sugar_box_in_frame\n",
    "\n",
    "\n",
    "    def prune_out_of_FOV(df, dataset):\n",
    "        # these don't move\n",
    "        episode = dataset.episodes[dataset.episodes.keys()[0]]\n",
    "        camera_num = 0\n",
    "        T_W_camera = episode.get_camera_pose_matrix(camera_num)\n",
    "        K = episode.get_K_matrix(camera_num)\n",
    "\n",
    "        in_frame_list = []\n",
    "        for index, row in df.iterrows():\n",
    "            object_position = row[\"object_position\"].strip(\"[\").strip(\"]\").split(\",\")\n",
    "            object_position = [float(x) for x in object_position]\n",
    "            object_position = np.asarray(object_position)\n",
    "\n",
    "            object_rpy = row[\"object_rpy\"].strip(\"[\").strip(\"]\").split(\",\")\n",
    "            object_rpy = [float(x) for x in object_rpy]\n",
    "\n",
    "            static_rotation_only = transformations.euler_matrix(0.0, 0.0, object_rpy[2], axes='sxyz')\n",
    "            static_rotation_only[0,3] = object_position[0]\n",
    "            static_rotation_only[1,3] = object_position[1]\n",
    "            static_rotation_only[2,3] = 2.00476981e-02\n",
    "            T_W_B = static_rotation_only\n",
    "            in_frame = check_sugar_box_in_frame(K, T_W_camera=T_W_camera, T_W_B=T_W_B, urange=[0,640], vrange=[0,480])\n",
    "\n",
    "            if not in_frame:\n",
    "                in_frame_list.append(False)\n",
    "            else:\n",
    "                in_frame_list.append(True)\n",
    "\n",
    "        df[\"in_frame\"] = in_frame_list\n",
    "        #print len(df)\n",
    "        #print len(df[df[\"in_frame\"] == True])\n",
    "        return df[df[\"in_frame\"] == True]\n",
    "\n",
    "    def adjust_reward(df):\n",
    "        df['reward'] += 1.2\n",
    "        df['reward'] = np.minimum(0.0,df['reward'])\n",
    "        return df\n",
    "\n",
    "    def create_distribution_plots(ax, df, dataset, min_r, max_r, first, use_yaw, ax_labels):\n",
    "\n",
    "        xs = []\n",
    "        ys = []\n",
    "        cs = []\n",
    "\n",
    "        episode = dataset.episodes[dataset.episodes.keys()[0]]\n",
    "        camera_num = 0\n",
    "        T_W_camera = episode.get_camera_pose_matrix(camera_num)\n",
    "        K = episode.get_K_matrix(camera_num)\n",
    "\n",
    "        # plot heatmap\n",
    "        for index, row in df.iterrows():\n",
    "            this_index = row[\"index\"]\n",
    "\n",
    "            object_position = row[\"object_position\"].strip(\"[\").strip(\"]\").split(\",\")\n",
    "            object_position = [float(x) for x in object_position]\n",
    "\n",
    "            object_rpy = row[\"object_rpy\"].strip(\"[\").strip(\"]\").split(\",\")\n",
    "            object_rpy = [float(x) for x in object_rpy]\n",
    "\n",
    "            object_position = np.asarray(object_position + object_rpy)\n",
    "\n",
    "            #jet = cm.get_cmap(\"jet\")\n",
    "            #jet = cm.get_cmap(\"coolwarm\")\n",
    "            #normed_reward = (-1.0*get_normed_reward(reward, min_r, max_r))+1.0\n",
    "            #normed_reward = get_normed_reward(reward, min_r, max_r)\n",
    "            if use_yaw:\n",
    "                x = object_position[5]\n",
    "            else:\n",
    "                x = object_position[0]\n",
    "            y = object_position[1]\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "            #cs.append(jet(normed_reward))\n",
    "            cs.append(row[\"reward\"])\n",
    "        [xs, ys, cs] = [np.asarray(x) for x in [xs,ys,cs]]\n",
    "\n",
    "        hm = ax.scatter(xs, ys, c=cs, vmin=-2.0, vmax=0, cmap = cm.coolwarm_r)\n",
    "        #hm = ax.scatter(ys, xs, c=cs, cmap = cm.coolwarm_r)\n",
    "        #plt.colorbar(hm)\n",
    "\n",
    "        # plot training examples\n",
    "        \n",
    "        yaw_train = []\n",
    "        y_train = []\n",
    "        for log_name in dataset.episodes.keys():\n",
    "\n",
    "            episode = dataset.episodes[log_name]\n",
    "\n",
    "            x = episode.get_entry(0)[\"observations\"][\"object_pose_cheat_data\"][\"position\"][\"x\"]\n",
    "            y = episode.get_entry(0)[\"observations\"][\"object_pose_cheat_data\"][\"position\"][\"y\"]\n",
    "            \n",
    "            T_W_B = spartan_utils.homogenous_transform_from_dict(episode.get_entry(0)['observations'][\"object_pose_cheat_data\"])\n",
    "            angle_axis = spartan_utils.angle_axis_from_rotation_matrix(T_W_B[:3,:3])\n",
    "            yaw = angle_axis[2]\n",
    "\n",
    "            if use_yaw:\n",
    "                x = yaw\n",
    "                \n",
    "            yaw_train.append(yaw)\n",
    "            y_train.append(y)\n",
    "\n",
    "\n",
    "            sc = ax.scatter(x, y, c=\"gray\", alpha=0.4, marker=\"x\")\n",
    "            \n",
    "        yaw_train = np.asarray(yaw_train)\n",
    "        y_train = np.asarray(y_train)\n",
    "        from scipy.spatial import ConvexHull\n",
    "        points = np.vstack((yaw_train,y_train)).transpose()\n",
    "        \n",
    "        hull = ConvexHull(points)\n",
    "        for simplex in hull.simplices:\n",
    "            ax.plot(points[simplex, 0], points[simplex, 1], ls='--', color=\"gray\")\n",
    "\n",
    "        #ax.axis('equal')\n",
    "        #ax.set(ylim=(-0.2, 0.2), xlim=(0.6, 0.7))\n",
    "        ax.set_title(row['name'])\n",
    "        if not first:\n",
    "            #ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        else:\n",
    "            ax.set_xlabel(ax_labels[0])\n",
    "            ax.set_ylabel(ax_labels[1])\n",
    "        return hm\n",
    "\n",
    "\n",
    "    dfs = []  \n",
    "\n",
    "\n",
    "    folders = []\n",
    "    for folder in sorted(os.listdir(os.path.join(spartan_source_dir, \"sandbox/experiment_02/logs-\"+NUM_LOGS))):\n",
    "        #print folder\n",
    "        if \"bak\" in folder or folder == \"05-endtoend\" or folder==\"01-gt-pose\":\n",
    "            continue\n",
    "        folders.append(folder)\n",
    "        path_to_move_to_box_folder = os.path.join(spartan_source_dir, \"sandbox\",\"experiment_02/logs-\"+NUM_LOGS,folder)\n",
    "        path_to_csv = os.path.join(path_to_move_to_box_folder, \"results.csv\")\n",
    "        df = pd.read_csv(path_to_csv, index_col=0)\n",
    "        df[\"name\"] = folder[3:]\n",
    "        dfs.append(df)\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        dfs[i] = prune_out_of_FOV(df, dataset)\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        dfs[i] = adjust_reward(df)    \n",
    "\n",
    "    min_r = 1e6\n",
    "    max_r = -1e6\n",
    "    for df in dfs:\n",
    "        this_min, this_max = get_min_max_rewards(df)\n",
    "        if this_min < min_r:\n",
    "            min_r = this_min\n",
    "        if this_max > max_r:\n",
    "            max_r = this_max\n",
    "\n",
    "    # SETTING THIS MANUALLY FOR SCALE\n",
    "    #min_r = -20\n",
    "    min_r = -5\n",
    "\n",
    "    # fig, axes = plt.subplots(ncols=len(dfs),nrows=1)\n",
    "    # fig.set_figheight(5)\n",
    "    # fig.set_figwidth(3* len(dfs))\n",
    "    # for i, df in enumerate(dfs):\n",
    "    #     if len(dfs) == 1:\n",
    "    #         ax = axes\n",
    "    #     else:\n",
    "    #         ax = axes[i]\n",
    "    #     if i == 0:\n",
    "    #         first = True\n",
    "    #     else:\n",
    "    #         first = False\n",
    "    #     ax_labels = (\"x, box position\", \"y, box position\")\n",
    "    #     hm = create_distribution_plots(ax, df, dataset, min, max, first=first, use_yaw=False, ax_labels=ax_labels)\n",
    "    # #plt.colorbar(hm, pad=0.2)\n",
    "\n",
    "    # cbaxes = fig.add_axes([0.92, 0.12, 0.02, 0.76]) \n",
    "    # cb = plt.colorbar(hm, cax = cbaxes) \n",
    "    # cb.set_label('Task success metric (higher is better)', labelpad=20, rotation=270)\n",
    "    # plt.show()\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=len(dfs),nrows=1)\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(3* len(dfs))\n",
    "    for i, df in enumerate(dfs):\n",
    "        if len(dfs) == 1:\n",
    "            ax = axes\n",
    "        else:\n",
    "            ax = axes[i]\n",
    "        if i == 0:\n",
    "            first = True\n",
    "        else:\n",
    "            first = False\n",
    "        ax_labels = (\"theta, box position\", \"y, box position\")\n",
    "        hm = create_distribution_plots(ax, df, dataset, min, max, first=first, use_yaw=True, ax_labels=ax_labels)\n",
    "    #plt.colorbar(hm, pad=0.2)\n",
    "\n",
    "    cbaxes = fig.add_axes([0.92, 0.12, 0.02, 0.76]) \n",
    "    cb = plt.colorbar(hm, cax = cbaxes) \n",
    "    cb.set_label('Task success metric (higher is better)', labelpad=20, rotation=270)\n",
    "    \n",
    "    fig.savefig(\"MTBSE2\"+NUM_LOGS+\".pdf\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style(\"white\", {\"axes.grid\": True})\n",
    "\n",
    "def plot_tensorflow_log(axis_pair, path, color, label, use_yaxis_label):\n",
    "\n",
    "    event_acc = EventAccumulator(path)#, tf_size_guidance)\n",
    "    event_acc.Reload()\n",
    "\n",
    "    # Show all tags in the log file\n",
    "    #print(event_acc.Tags())\n",
    "\n",
    "    training_accuracies =   event_acc.Scalars('loss')\n",
    "    validation_accuracies = event_acc.Scalars('test_loss_average')\n",
    "\n",
    "    x_train_steps = []\n",
    "    x_train_values = []\n",
    "    \n",
    "    \n",
    "    for i in xrange(len(training_accuracies)):\n",
    "        x_train_steps.append(training_accuracies[i][1]) # 1 is step\n",
    "        x_train_values.append(training_accuracies[i][2]) # 2 is step\n",
    "    \n",
    "#     from scipy.signal import savgol_filter\n",
    "#     x_train_values_filt = savgol_filter(x_train_values, 21, 2)\n",
    "\n",
    "    #from scipy.signal import medfilt\n",
    "    #x_train_values_filt = medfilt(x_train_values, 21)\n",
    "    \n",
    "    w = 0.90\n",
    "    x_train_values = np.asarray(x_train_values)\n",
    "    x_train_values_filt = x_train_values*0.0\n",
    "    x_train_values_filt[0] = x_train_values[0]\n",
    "    for i, v in enumerate(x_train_values[1:]):\n",
    "        x_train_values_filt[i+1] = x_train_values_filt[i]*w + (1-w)*x_train_values[i]\n",
    "   \n",
    "    \n",
    "#     from scipy import signal\n",
    "#     xn = x_train_values\n",
    "#     b, a = signal.butter(3, 0.05)\n",
    "#     zi = signal.lfilter_zi(b, a)\n",
    "#     z, _ = signal.lfilter(b, a, xn, zi=zi*xn[0])\n",
    "#     z2, _ = signal.lfilter(b, a, z, zi=zi*z[0])\n",
    "#     y = signal.filtfilt(b, a, xn)\n",
    "#     x_train_values_filt = y\n",
    "\n",
    "        \n",
    "    x_validation_steps = []\n",
    "    x_validation_values = []\n",
    "    \n",
    "    for i in xrange(len(validation_accuracies)):\n",
    "        x_validation_steps.append(validation_accuracies[i][1])\n",
    "        x_validation_values.append(validation_accuracies[i][2])\n",
    "        \n",
    "\n",
    "    axis_pair[0].plot(np.asarray(x_train_steps), np.asarray(x_train_values_filt), color=color, label=label, alpha=1.0)\n",
    "    axis_pair[0].plot(np.asarray(x_train_steps), np.asarray(x_train_values), color=color, alpha=0.1)\n",
    "    axis_pair[1].plot(np.asarray(x_validation_steps), np.asarray(x_validation_values), label=label, color=color)\n",
    "\n",
    "    #axis_pair[0].set_xlabel(\"Steps\")\n",
    "    axis_pair[1].set_xlabel(\"Steps\")\n",
    "    if use_yaxis_label:\n",
    "        axis_pair[0].set_ylabel(\"Loss\")\n",
    "        axis_pair[1].set_ylabel(\"Loss\")\n",
    "    axis_pair[0].set_xticks([])\n",
    "    #axis_pair[0].set_title(\"Train\")\n",
    "    axis_pair[0].set(ylim=(0.5e-4, 1.5e-4))\n",
    "    axis_pair[1].set(ylim=(0.5e-4, 1.5e-4))\n",
    "    #axis_pair[1].set_title(\"Validation\")\n",
    "\n",
    "\n",
    "def get_tf_events_file(path):\n",
    "    return sorted(os.listdir(path))[-1]\n",
    "    \n",
    "fig, axes = plt.subplots(nrows=2,ncols=4)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "\n",
    "\n",
    "#colors = [\"black\", \"red\", \"orange\", \"green\", \"blue\", \"purple\"]\n",
    "colors = [\"red\", \"orange\", \"blue\", \"green\", \"purple\"]\n",
    "\n",
    "#folders.insert(0,\"00-blind\")\n",
    "\n",
    "def folder_to_plot_name(name):\n",
    "    if name == \"gt-3D-points\":\n",
    "        return \"Ground truth 3D points\"\n",
    "    if name == \"gt-3D-points-projected\":\n",
    "        return \"Ground truth 2D image coordinates\"\n",
    "    if name == \"endtoend-fullwidth\":\n",
    "        return \"End-to-End\"\n",
    "    else:\n",
    "        return \"Dense Descriptors\"\n",
    "\n",
    "\n",
    "for num_index, NUM_LOGS in enumerate([\"30\", \"50\", \"100\", \"200\"]):\n",
    "    base = os.path.join(data_dir, \"pdc/imitation/trained_models/mlp_position/experiment_02-aug12-logs-\"+NUM_LOGS)\n",
    "    folders = []\n",
    "    for folder in sorted(os.listdir(os.path.join(spartan_source_dir, \"sandbox/experiment_02/logs-\"+NUM_LOGS))):\n",
    "        #print folder\n",
    "        if \"bak\" in folder or folder == \"05-endtoend\" or folder==\"01-gt-pose\":\n",
    "            continue\n",
    "        folders.append(folder)\n",
    "\n",
    "    counter = 0\n",
    "    for color, folder in zip(colors, folders):\n",
    "        counter+=1\n",
    "        path_to = os.path.join(base,folder,\"tensorboard\")\n",
    "        tf_file = get_tf_events_file(path_to)\n",
    "        tf_file_full = os.path.join(path_to, tf_file)\n",
    "        print tf_file_full\n",
    "        axis_pair = [axes[0, num_index], axes[1,num_index]]\n",
    "        use_yaxis_label = (num_index==0)\n",
    "        plot_tensorflow_log(axis_pair, tf_file_full, color, label=folder_to_plot_name(folder[3:]), use_yaxis_label=use_yaxis_label)\n",
    "    #     if counter == 2:\n",
    "    #         break\n",
    "\n",
    "    axes[0,num_index].ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    axes[1,num_index].ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "#lgd = axes[0,3].legend(loc='upper right', bbox_to_anchor=(-2.4,3.0),frameon=True)\n",
    "lgd = axes[0,3].legend(loc='upper right', bbox_to_anchor=(2.4,1.05), frameon=True)\n",
    "\n",
    "fig.savefig(\"MTBSE2-samplecomplexity-traintest2.pdf\", bbox_inches=\"tight\")\n",
    "#fig.savefig('MTBSE2-samplecomplexity-traintest2.pdf', bbox_extra_artists=(lgd), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Training times\"\n",
    "print \"---------------\"\n",
    "import datetime\n",
    "\n",
    "for folder in folders:\n",
    "    path_to = os.path.join(base,folder,\"tensorboard\")\n",
    "    tf_file = get_tf_events_file(path_to)\n",
    "    tf_file_full = os.path.join(path_to, tf_file)\n",
    "    event_acc = EventAccumulator(tf_file_full)#, tf_size_guidance)\n",
    "    event_acc.Reload()\n",
    "    training_accuracies =   event_acc.Scalars('loss')\n",
    "    seconds = training_accuracies[-1][0] - training_accuracies[0][0]\n",
    "    #print str(datetime.timedelta(seconds=seconds)) \n",
    "    #print '%d hr, %d minutes, %02d seconds' % (seconds / 60 / 60,  seconds/ 60 % 60, seconds % 60)\n",
    "    print '{:25}'.format(folder[3:]),  '%d hr, %d minutes' % (seconds / 60 / 60,  seconds/ 60 % 60)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_drift_plot(dfs):\n",
    "    for df in dfs:\n",
    "        plt.scatter(df[\"index\"], df[\"termination_time\"])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.scatter(dfs[-1][\"index\"], df[\"termination_time\"])\n",
    "    plt.show()\n",
    "    \n",
    "create_time_drift_plot(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "def create_violin_plot(dfs):\n",
    "    df_all = pd.concat(dfs)\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    ax = sns.violinplot(x=df_all[\"name\"], y=df_all[\"reward\"])\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(15, 4)\n",
    "    plt.show()\n",
    "    \n",
    "create_violin_plot(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# great example: https://seaborn.pydata.org/examples/distplot_options.html\n",
    "# full documentation: https://seaborn.pydata.org/generated/seaborn.distplot.html\n",
    "def create_dist_plot(dfs):\n",
    "    df_all = pd.concat(dfs)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(dfs), figsize=(9, 3), sharey=True)\n",
    "    \n",
    "    \n",
    "    #axes[0].set_ylim([-20,0])\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    for i, df in enumerate(dfs):\n",
    "#         if not isinstance(axes, list):\n",
    "#             this_ax = axes\n",
    "#         else:\n",
    "#             this_ax = axes[i]\n",
    "        this_ax = axes[i]\n",
    "        sns.distplot(df[\"reward\"], vertical=True, ax=this_ax, bins=20)\n",
    "        #ax = sns.violinplot(x=df_all[\"name\"], y=df_all[\"reward\"])\n",
    "        #fig = matplotlib.pyplot.gcf()\n",
    "        #fig.set_size_inches(18.5, 10.5)\n",
    "    plt.show()\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(dfs), figsize=(9, 3), sharey=True)\n",
    "#     if not isinstance(axes, list):\n",
    "#         axes.set_ylim([-2,-1])\n",
    "#     else:\n",
    "#         axes[0].set_ylim([-2,-1])\n",
    "    \n",
    "    sns.set(style=\"whitegrid\")\n",
    "    for i, df in enumerate(dfs):\n",
    "#         if not isinstance(axes, list):\n",
    "#             this_ax = axes\n",
    "#         else:\n",
    "        this_ax = axes[i]\n",
    "        sns.distplot(df[\"reward\"], vertical=True, ax=this_ax, bins=20, rug=True)\n",
    "        #ax = sns.violinplot(x=df_all[\"name\"], y=df_all[\"reward\"])\n",
    "        #fig = matplotlib.pyplot.gcf()\n",
    "        #fig.set_size_inches(18.5, 10.5)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "create_dist_plot(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
